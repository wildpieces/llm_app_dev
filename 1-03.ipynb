{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리\n",
    "Huggingface팀이 개발한 트랜스포머 라이브러리는 공통된 인터페이스로 트랜스포머 모델을 활용할 수 있도록 지원함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스 트랜스포머 활용에 필요한 라이브러리 설치\n",
    "# pip install transformers==4.50.0 datasets==3.5.0 huggingface_hub==0.29.0 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 허깅페이스 트랜스포머란\n",
    "다양한 트랜스포머 모델을 통일된 인터페이스로 사용할 수 있도록 지원하는 오픈소스 라이브러리 <br>\n",
    "- transformers 라이브러리: 트렌스포머 모델과 토크나이저를 활용할 때 사용\n",
    "- datasets 라이브러리: 데이터셋을 공개하고 쉽게 가져다 쓸 수 있도록 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT와 GPT-2모델을 활용할 때 허깅페이스 트랜스포머 코드 비교\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "text = \"What is Huggingface Transformers?\"\n",
    "# BERT 모델 활용\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\") # 모델 불러오기\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') # 토크나이저 불러오기\n",
    "encoded_input = bert_tokenizer(text, return_tensors='pt') # 입력 토큰화\n",
    "bert_output = bert_model(**encoded_input) # 모델에 입력\n",
    "\n",
    "# GPT-2 모델 활용\n",
    "gpt_model = AutoModel.from_pretrained('gpt2') # 모델 불러오기\n",
    "gtp_tokenizer = AutoTokenizer.from_pretrained('gpt2') # 토크나이저 불러오기\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt') # 입력 토큰화\n",
    "gpt_output = gpt_model(**encoded_input) # 모델에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Default)",
   "language": "python",
   "name": "python-default"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
